{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# #QuickGrab \n",
    "\n",
    "#### For cases where I open the file for the ONLY purpose of copying important code.\n",
    "\n",
    "*This markdown cell and the following code cell were created after finishing this whole script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.2149727344513\n"
     ]
    }
   ],
   "source": [
    "from pj_funcs import *\n",
    "\n",
    "# Import past few days' PHESS data\n",
    "file = pd.read_csv('../data/raw/export.csv', encoding = 'Cp1252')\n",
    "\n",
    "# impliment my custom ADT-parsing function\n",
    "df = NSSP_Element_Grabber(file,Timed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NSSP Element Grabber Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NSSP_Element_Grabber(data,Timed = True, Priority_only=False, outfile='None'):\n",
    "    '''\n",
    "    Creates dataframe of important elements from PHESS data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data: pandas DataFrame, required, from PHESS sql pull\n",
    "    \n",
    "    Timed:  Default is True.  Prints total runtime at end.\n",
    "    Priority_only:  Default is False.  \n",
    "        If True, only gives priority 1 or 2 elements\n",
    "    outfile:  Default is 'None':\n",
    "        Replace with file name for dataframe to be wrote to as csv\n",
    "        DO NOT INCLUDE .csv IF YOU CHOOSE TO MAKE ONE\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dataframe\n",
    "        \n",
    "    Requirements\n",
    "    ------------\n",
    "    - import pandas as pd\n",
    "    - import numpy as np\n",
    "    - import time\n",
    "    '''\n",
    "    # Start our runtime clock.\n",
    "    start_time = time.time()\n",
    "    \n",
    "    \n",
    "    # Read in reader file as pandas dataframe\n",
    "    reader = pd.read_excel('../data/processed/NSSP_Element_Reader.xlsx')\n",
    "    \n",
    "    # Create empty dataframe with rows we want interpreted from reader file\n",
    "    df = pd.DataFrame(columns=reader['Processed Column'])\n",
    "    \n",
    "    # Create a few extra columns straight from our data file\n",
    "    df['MESSAGE'] = data['MESSAGE']\n",
    "    df['FACILITY_NAME'] = data['FACILITY_NAME']\n",
    "    df['PATIENT_VISIT_NUMBER'] = data['PATIENT_VISIT_NUMBER']\n",
    "    df['PATIENT_MRN'] = data['PATIENT_MRN']\n",
    "\n",
    "    # Create a subset of rows from our reader file.  Only ones to loop through.\n",
    "    # Order by 'Group_Order' so that some run before others that rely on previous.\n",
    "    reader_sub = reader[reader.Ignore == 0].sort_values('Group_Order')\n",
    "\n",
    "    # Loop through all data rows\n",
    "    for z in np.arange(0,len(data)):\n",
    "        \n",
    "        # Locate our message\n",
    "        message = df['MESSAGE'][z]\n",
    "        \n",
    "        # Decipher using hl7 function\n",
    "        m = hl7.parse(message)\n",
    "        \n",
    "        # For each row in our reader file subset\n",
    "        for j in np.arange(0,len(reader_sub)):\n",
    "            \n",
    "            # Initialize object.  Don't want one recycled from last loop\n",
    "            obj=''\n",
    "            \n",
    "            # Choose the row we will use from the reader file\n",
    "            row = reader_sub.iloc[j]\n",
    "            \n",
    "            # Identify element name we're working with.  Also a column name in output dataframe\n",
    "            col_name = str(row['Processed Column'])\n",
    "            \n",
    "            # Identify code from our reader file we use to find the element in the HL7 message\n",
    "            subcode = row['Code']\n",
    "            \n",
    "            # Does executing this code (originally a string) cause an error?\n",
    "            ### NOTE:  calling locals and globals allows you to access all home-grown functions\n",
    "            if NoError(exec,subcode,globals(), locals()):\n",
    "                \n",
    "                # If no errors, execute the code.\n",
    "                exec(subcode,globals(), locals())\n",
    "                \n",
    "    # End time stopwatch\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Unless they did not want it, print runtime\n",
    "    if Timed != False:\n",
    "        print(end_time-start_time)\n",
    "    \n",
    "    # If they only want priority elements:\n",
    "    if Priority_only==True:\n",
    "        # left = all columns interpreted from reader file\n",
    "        left = df.iloc[:,:-4] \n",
    "        # right = MESSAGE, FACNAME, PATIENT_VN, PATIENT_MRN\n",
    "        right = df.iloc[:,-4:]\n",
    "        # find all cols we want from reader file. Priority cols\n",
    "        priority_cols = reader['Processed Column'][(reader['Priority'] == 1.0)|(reader['Priority'] == 2.0)]\n",
    "        # Index our left set by these columns \n",
    "        col_cut = left.loc[:,priority_cols]\n",
    "        # glue left indexed with right again\n",
    "        df = col_cut.join(right)\n",
    "        \n",
    "    # If they want an output file...\n",
    "    if outfile!='None':\n",
    "        # Specify output path and add csv bit.\n",
    "        outpath = '../data/processed/'+outfile+'.csv'\n",
    "        # No index\n",
    "        df.to_csv(outpath, index=False)\n",
    "    \n",
    "    # return the dataframe!\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# README\n",
    "\n",
    "#### Above, we have the main function that I use to parse an HL7 message for NSSP Priority Elements.  For each message in a dataset, I loop through a seperate dataframe (the reader file) that has important code that I use to locate an element within an HL7 message.  The exec() function allows me to acess this code and impliment it. \n",
    "\n",
    "#### All material below mostly describes each Element's code.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Core concepts to understand.\n",
    "* I use an Excel Document as a 'reader' file.  Within this file:\n",
    "    * Each row represents a NSSP Priority Element OR something to help support a NSSP element.  Supporting info can be a data type description, the data source of a specific element, or even a separate element within the list of a heirchally defined element.  \n",
    "    * Important columns are:\n",
    "        * Processed Column - Name of Element.  Will be in outputted dataframe.\n",
    "        * HL7 Processed Element Description - Describes steps for how to locate an element within the HL7 message.\n",
    "        * <b>Code - The python code as a string that will be executed in our main HL7 parsing function.</b>\n",
    "        * Priority - Defined by NSSP.  1,2, or NaN (for supporting elements)\n",
    "        * Group_Order - The order in which to find elements.  Elements that require supporting element information have a later order.\n",
    "        * Ignore - 0 or 1.  1 indicates it WILL be ignored.  0 indicates that we will call it in our main HL7 Parsing function.  When ignore=0, the row contains valid Code.\n",
    "   \n",
    "* The code in our excel file is read in as a string in Python using a pandas.read_excel() function.  \n",
    "    * The string is then interpreted as code using the exec('string') function.\n",
    "\n",
    "* The code in the excel file is ugly and not annotated so that the exec() function doesn't have to repeatedly think to interperet new lines and comments.\n",
    "    * The code is copied here. (How it looks)\n",
    "    * An <u>annotated</u> version is also kept here (Annotated Version)\n",
    "\n",
    "* If you are confused as to how an element is attained, use `CTRL+F` to search for it specifically in this document\n",
    "\n",
    "<hr style=\"border:1px solid gray\"> </hr>\n",
    "\n",
    "\n",
    "\\* Functions that work for multiple elements have example codes.  You may see something say \n",
    "\n",
    "`Field = ['ABC']`\n",
    "\n",
    "This is just an example, there is no field called ABC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before the following codes executed in our main function's loop, we have already defined the following terms:\n",
    "* m = hl7.parse(message)\n",
    "* z = integer representing the row index\n",
    "* col_name = current element being coded.  Also column name\n",
    "\n",
    "\n",
    "<hr style=\"border:5px solid gray\"> </hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DI_One()\n",
    "\n",
    "This function is the simplest situation:  where the HL7 Element is found in one described location directly inputted from the message.\n",
    "\n",
    "### Direct Input from HL7 - One Element\n",
    "\n",
    "\n",
    "16/43 fit this criteria\n",
    "\n",
    "<ul>\n",
    "    <li>Visit_ID </li>\n",
    "    <li>Treating_Facility_ID   </li>\n",
    "    <li>Admit_Date_Time (only take 1st 12 chars for datetime uniformity) </li>\n",
    "    <li>Patient_Class_Code   </li>\n",
    "    <li>Patient_Zip   </li>\n",
    "    <li>Processing_ID   </li>\n",
    "    <li>Trigger_Event   </li>\n",
    "    <li>Message_Date_Time   </li>\n",
    "    <li>Recorded_Date_Time   </li>\n",
    "    <li>Discharge_Disposition   </li>\n",
    "    <li>Discharge_Date_Time   </li>\n",
    "    <li>Administrative_Sex   </li>\n",
    "    <li>Patient_City   </li>\n",
    "    <li>Patient_State  </li>\n",
    "    <li>Patient_Country   </li>\n",
    "    <li>Version_ID   </li>\n",
    "\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All of the mentioned elements above use the following function DI_One(ind,m,df,z,col_name) \n",
    "\n",
    "for more info on the function, run the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DI_One?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# How it looks  \n",
    "########################\n",
    "\n",
    "ind = ['ABC',1,1,1,1]\n",
    "DI_One(ind,m,df,z,col_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# Annotated Version \n",
    "########################\n",
    "\n",
    "# Choose exact HL7 path to element beginning with field\n",
    "ind = ['ABC',1,1,1,1]\n",
    "\n",
    "# Execute DI_One() function using the (index,message,dataframe,row_z,column_name)\n",
    "DI_One(ind,m,df,z,col_name) \n",
    "\n",
    "### NOTE:  This function updates the respective cell in the dataframe 'df'.  See function's description for more detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct Input from HL7 - 1st non-null of Two Elements (NO CONCETATION)\n",
    "\n",
    "Here we describe a situation where we have been given two locations.  If an element exists in the first location, we use it to define our element.  Otherwise, search the second location and do the same thing.\n",
    "\n",
    "3/43 \n",
    "\n",
    "<ul>\n",
    "    <li>Sending_Facility_ID  </li>\n",
    "    <li>First_Patient_ID  </li>\n",
    "    <li>Admit_Reason_Code  </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# How it looks  \n",
    "########################\n",
    "\n",
    "ind = ['ABC',0,0,0,0]\n",
    "ind2 = ['DEF',1,1,1,1]\n",
    "obj = DI_One(ind,m,df,z,col_name)\n",
    "if len(obj)==0:\n",
    "    DI_One(ind2,m,df,z,col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# Annotated Version \n",
    "########################\n",
    "\n",
    "# Specify full index of 1st in hierarchy \n",
    "ind = ['ABC',0,0,0,0]\n",
    "\n",
    "# Specify full index of 2nd in hierarchy \n",
    "ind2 = ['DEF',1,1,1,1]\n",
    "\n",
    "# Run our DI_One function to pull element from message with path 'ind'\n",
    "obj = DI_One(ind,m,df,z,col_name)\n",
    "\n",
    "# If this doesn't work, do same but with 'ind2'\n",
    "if len(obj)==0:\n",
    "    DI_One(ind2,m,df,z,col_name)\n",
    "\n",
    "\n",
    "### NOTE:  This function updates the respective cell in the dataframe 'df'.  See function's description for more detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DI_One_CONC()\n",
    "\n",
    "### Direct Input from HL7 - One Element (WITH CONCETATION)\n",
    "\n",
    "There is only one case where this is used directly.  It is when we pull our information directly from one location, but the field may repeat which requires concatinating elements.\n",
    "\n",
    "1/43\n",
    "\n",
    "<ul>\n",
    "    <li>Diagnosis_Type  </li>\n",
    "</ul>\n",
    "\n",
    "#### The mentioned element above uses the following function DI_One_CONC(field,ind,m,df,z,col_name) \n",
    "\n",
    "for more info on the function, run the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DI_One_CONC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# How it looks  \n",
    "########################\n",
    "\n",
    "field = ['ABC']\n",
    "ind = [0,0,0]\n",
    "DI_One_CONC(field,ind,m,df,z,col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# Annotated Version \n",
    "########################\n",
    "\n",
    "# Specify field as 1 element list\n",
    "field = ['ABC']\n",
    "\n",
    "# Specify rest of indeces\n",
    "ind = [0,0,0]\n",
    "\n",
    "# Execute DI_One() function using the (field,rest_of_index,message,dataframe,row_z,column_name)\n",
    "DI_One_CONC(field,ind,m,df,z,col_name)\n",
    "\n",
    "\n",
    "### NOTE:  This function updates the respective cell in the dataframe 'df'.  See function's description for more detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct Input from HL7 - 1st non-null of Two Elements (WITH CONCETATION)\n",
    "\n",
    "Similar to our other '1st non-null of two elements' definition but this time with the option of a repeating field whos elements can be concatenated.\n",
    "\n",
    "6/43\n",
    "\n",
    "<ul>\n",
    "    <li>Admit_Reason_Description  </li>\n",
    "    <li>Diagnosis_Code  </li>\n",
    "    <li>Diagnosis_Description  </li>\n",
    "    <li>Race_Code      </li>\n",
    "    <li>Ethnicity_Code       </li>\n",
    "    <li>Ethnicity_Description       </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# How it looks  \n",
    "########################\n",
    "\n",
    "field = ['ABC']\n",
    "ind = [0,0,0]\n",
    "field2 = ['DEF']\n",
    "ind2 = [1,1,1]\n",
    "obj = DI_One_CONC(field,ind,m,df,z,col_name)\n",
    "if len(obj)==0:\n",
    "    DI_One_CONC(field2,ind2,m,df,z,col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# Annotated Version \n",
    "########################\n",
    "\n",
    "# Specify full index of 1st in hierarchy.  Since CONC required, do field and ind separately.\n",
    "field = ['ABC']\n",
    "ind = [0,0,0]\n",
    "\n",
    "# Specify full index of 2nd in hierarchy.  Since CONC required, do field and ind separately.\n",
    "field2 = ['DEF']\n",
    "ind2 = [1,1,1]\n",
    "\n",
    "# Run our DI_One_CONC function to pull element from message with path 'field' / 'ind'\n",
    "obj = DI_One_CONC(field,ind,m,df,z,col_name)\n",
    "\n",
    "# If empty, our DI_One_CONC function to pull element from message with path 'field2' / 'ind2'\n",
    "if len(obj)==0:\n",
    "    DI_One_CONC(field2,ind2,m,df,z,col_name)\n",
    "    \n",
    "### NOTE:  This function updates the respective cell in the dataframe 'df'.  See function's description for more detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
    "# ONE BY ONE\n",
    "\n",
    "\n",
    "### For each NSSP Priority element below, we describe a unique code on how to access it from a HL7 message.  Some peices of code will write multiple elements to our output dataframe at once:\n",
    "\n",
    "#### Example:  Reported_Age_Units is found at the same time as Reported_Age for the sake of saving computing runtime\n",
    "# xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C_Unique_Patient_ID\n",
    "--------------------\n",
    "Field must be populated.  If not populated, record is sent to the Exceptions table.\n",
    "\n",
    "Scan the following fields/ HL7 segments and select the first non-null value:\n",
    "* Medical_Record_Number\n",
    "* Patient ID (PID-2.1) [Legacy]\n",
    "* First_Patient_ID (PID-3)\n",
    "* Patient_Account_Number (PID-18) \n",
    "* Visit_Number (PV1-19)\n",
    "\n",
    "\n",
    "\\* Also outputs C_Unique_Patient_ID_Data_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# How it looks  \n",
    "########################\n",
    "\n",
    "colz = ['Medical_Record_Number','Patient_ID','First_Patient_ID','Patient_Account_Number','Visit_ID']\n",
    "for col in colz:\n",
    "    var = df.loc[z,col]\n",
    "    if var == var:\n",
    "        df.loc[z,col_name] = var\n",
    "        df.loc[z,(col_name+'_Data_Source')] = col\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# Annotated Version \n",
    "########################\n",
    "\n",
    "\n",
    "# Specify columns in hierarchical order.  first choice -> last choice\n",
    "colz = ['Medical_Record_Number','Patient_ID','First_Patient_ID','Patient_Account_Number','Visit_ID']\n",
    "\n",
    "# Loop through our heirchical options\n",
    "for col in colz:\n",
    "    \n",
    "    # Select our value of this element in the current row, z\n",
    "    var = df.loc[z,col]\n",
    "    \n",
    "    # If non-null, then we update this rows' C_Unique_Patient_ID cell and track our Data Source. Once we do this, break the loop.\n",
    "    if var == var:\n",
    "        df.loc[z,col_name] = var\n",
    "        df.loc[z,(col_name+'_Data_Source')] = col\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facility_Type_Code\n",
    "--------------------\n",
    "OBX-5 Segment where\n",
    "* OBX-3 Observation Identifier SS003^Facility/visit type\n",
    "* OBX-2=\"CWE\"\n",
    "\n",
    "Populate this field with the OBX-5.1 value (standard code) if it exists. ELSE use the OBX-5.4 (local code) value.\n",
    "\n",
    "If more than one OBX segment is sent that contains facility type information, only the FIRST OBX segment will be considered.\n",
    "\n",
    " \\*Also outputs Facility_Type_Code_OBX2\n",
    " \\*Also outputs Facility_Type_Code_OBX3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# How it looks  \n",
    "########################\n",
    "\n",
    "if NoError(index,m,'OBX'):\n",
    "    obxs = m['OBX']\n",
    "    pat = 'SS003'\n",
    "    pattern = re.compile(pat,re.M|re.I)\n",
    "    for q in np.arange(0,len(obxs)):\n",
    "        five = ''\n",
    "        obx = obxs[q]\n",
    "        searchme = str(obx)\n",
    "        match = re.findall(pattern,searchme)\n",
    "        num_matches = len(match)\n",
    "        if num_matches > 0:\n",
    "            two = str(obx[2])\n",
    "            three = str(obx[3])\n",
    "            five = obx[5]\n",
    "            if len(str(five[0])) > 0:\n",
    "                while type(five) != str:\n",
    "                    five = five[0]\n",
    "            else:\n",
    "                five = str(five[3])\n",
    "                \n",
    "            if len(five)>0:\n",
    "                df.loc[z,col_name] = five\n",
    "                df.loc[z,col_name+'_OBX2'] = two\n",
    "                df.loc[z,col_name+'_OBX3'] = three\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# Annotated Version\n",
    "########################\n",
    "\n",
    "\n",
    "# Check to see we can index OBX\n",
    "if NoError(index,m,'OBX'):\n",
    "    \n",
    "    # Get list of all repeated OBX fields\n",
    "    obxs = m['OBX']\n",
    "    \n",
    "    # Specify key pattern to look for in OBX field's string and compile in RegEx\n",
    "    pat = 'SS003'\n",
    "    pattern = re.compile(pat,re.M|re.I)\n",
    "    \n",
    "    # Loop through all repeated OBX fields\n",
    "    for q in np.arange(0,len(obxs)):\n",
    "        \n",
    "        # Initialize OBX5\n",
    "        five = ''\n",
    "        # Select current obx field and create a string copy of it\n",
    "        obx = obxs[q]\n",
    "        searchme = str(obx)\n",
    "        \n",
    "        # Check to see if the pattern is in the string match\n",
    "        match = re.findall(pattern,searchme)\n",
    "        num_matches = len(match)\n",
    "        \n",
    "        # If there is a match...\n",
    "        if num_matches > 0:\n",
    "            \n",
    "            # Pick out OBX2, OBX3, OBX5\n",
    "            two = str(obx[2])\n",
    "            three = str(obx[3])\n",
    "            five = obx[5]\n",
    "            \n",
    "            # If five[0] is non-empty, index it with a 0 until it is a string\n",
    "            if len(str(five[0])) > 0:\n",
    "                while type(five) != str:\n",
    "                    five = five[0]\n",
    "            \n",
    "            # Otherwise, choose five[3]\n",
    "            else:\n",
    "                five = str(five[3])\n",
    "    \n",
    "            \n",
    "            # Append respective OBX5.# if it is non-empty.\n",
    "            # Also append OBX2 and OBX3 to Facility_Type_Code_OBX# respectively for option to later do a data validity test \n",
    "            if len(five)>0:\n",
    "                df.loc[z,col_name] = five\n",
    "                df.loc[z,col_name+'_OBX2'] = two\n",
    "                df.loc[z,col_name+'_OBX3'] = three2\n",
    "                \n",
    "                # \"If more than one OBX segment is sent that contains facility type information, only the FIRST OBX segment will be considered\" \n",
    "                break\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chief_Complaint_Text\n",
    "--------------------\n",
    "OBX-5 segments where:\n",
    "* OBX-3 Observation Identifier is 8661-1 and/or 11292-0\n",
    "* OBX-2 = \"TX\" or \"CWE\" or \"CW\"\n",
    "\n",
    "Select all non-null values and concatenate:\n",
    "IF OBX-2=\"TX\" then Chief_Complaint_Text = OBX-5.1\n",
    "IF OBX-2=\"CWE\" or \"CW\" then Chief_Complaint_Text = concatenate(OBX-5.9, OBX-5.2, OBX-5.5)\n",
    "\n",
    " \\*Also outputs Chief_Complaint_Text_OBX2\n",
    "\n",
    "\\*Also outputs Chief_Complaint_Text_OBX3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTANT NOTE - \n",
    "\n",
    "Reading the description above, we see that there is a chance that we will have multiple chief complaint fields.  If this is the case, we will have to concatenate the multiple fields.  We will denote this field concetation with the '|' character.\n",
    "\n",
    "There is also a chance that if OBX-2 = CW/CWE we will have to concatenate multiple subcomponents.  We will denote this sub-concetation with a '^' character.\n",
    "\n",
    "While it is rare for the Chief Complaint field to repeat, there is a chance that we will end up with a chief_complaint_text similar to the example below.\n",
    "\n",
    "`CC_Text = OBX.1.5.9^OBX.1.5.2^OBX.1.5.5 | OBX.4.5.9^OBX.4.5.2^OBX.4.5.5`\n",
    "\n",
    "Above the repeating field is OBX|1| and OBX|4|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# How it looks  \n",
    "########################\n",
    "\n",
    "pat = '(8661-1)|(11292-0)'\n",
    "pattern = re.compile(pat,re.M|re.I)\n",
    "fives = []\n",
    "twos = []\n",
    "threes = []\n",
    "if NoError(index,m,'OBX'):\n",
    "    sect = index(m,'OBX')\n",
    "    for j in np.arange(0,len(sect)):\n",
    "        obx = sect[j]\n",
    "        searchme = str(obx)\n",
    "        match = re.findall(pattern,searchme)\n",
    "        two = ''\n",
    "        three = ''\n",
    "        five = ''\n",
    "        if len(match)>0:\n",
    "            if NoError(index,obx,2) & NoError(index,obx,3) & NoError(index,obx,5):\n",
    "                two = str(obx[2])\n",
    "                three = str(obx[3])\n",
    "                if (two == 'CW')|(two == 'CWE'):\n",
    "                    pt1 = ''\n",
    "                    pt2 = ''\n",
    "                    pt3 = ''\n",
    "                    five = obx[5]\n",
    "                    if NoError(index_n,five,[0,8]):\n",
    "                        pt1 = str(index_n(five,[0,8]))\n",
    "                    if NoError(index_n,five,[0,1]):\n",
    "                        pt2 = str(index_n(five,[0,1]))\n",
    "                    if NoError(index_n,five,[0,4]):\n",
    "                        pt3 = str(index_n(five,[0,4]))\n",
    "                        \n",
    "                    fife_dog = '^'.join([pt1,pt2,pt3])\n",
    "                    if len(fife_dog.replace('^',''))>0:\n",
    "                        fives.append(fife_dog)\n",
    "                        twos.append(two)\n",
    "                        threes.append(three)\n",
    "                elif (two == 'TX'):\n",
    "                    five = obx[5]\n",
    "                    while type(five) != str:\n",
    "                        five = five[0]\n",
    "                    fives.append(five)\n",
    "                    twos.append(two)\n",
    "                    threes.append(three)\n",
    "\n",
    "    entry_5 = '|'.join(fives)\n",
    "    entry_2 = '|'.join(twos)\n",
    "    entry_3 = '|'.join(threes)\n",
    "    \n",
    "    if len(entry_5)>0:\n",
    "        df.loc[z,col_name] = entry_5\n",
    "        df.loc[z,col_name+'_OBX2'] = entry_2\n",
    "        df.loc[z,col_name+'_OBX3'] = entry_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# Annotated Version \n",
    "########################\n",
    "\n",
    "# Specify pattern and compile in RegEx\n",
    "pat = '(8661-1)|(11292-0)'\n",
    "pattern = re.compile(pat,re.M|re.I)\n",
    "\n",
    "# Create empty array for concentated elements to be appended to.  Later merged into 1 string\n",
    "fives = []\n",
    "twos = []\n",
    "threes = []\n",
    "\n",
    "# Check to see if OBX can be indexed into\n",
    "if NoError(index,m,'OBX'):\n",
    "    \n",
    "    # If so, define obx field as 'sect'\n",
    "    sect = index(m,'OBX')\n",
    "    \n",
    "    #  Loop through repeated OBX fields\n",
    "    for j in np.arange(0,len(sect)):\n",
    "        \n",
    "        # Define obx field in question as 'obx' and create string copy of it called 'searchme'\n",
    "        obx = sect[j]\n",
    "        searchme = str(obx)\n",
    "        \n",
    "        # Search for RegEx keyword matches within obx string\n",
    "        match = re.findall(pattern,searchme)\n",
    "        \n",
    "        # Initialize OBX2,3,5\n",
    "        two = ''\n",
    "        three = ''\n",
    "        five = ''\n",
    "        \n",
    "        # If we have any matches....\n",
    "        if len(match)>0:\n",
    "            \n",
    "            # Check to see if OBX2,OBX3,and OBX5 exist\n",
    "            if NoError(index,obx,2) & NoError(index,obx,3) & NoError(index,obx,5):\n",
    "                \n",
    "                # Define OBX2,3\n",
    "                two = str(obx[2])\n",
    "                three = str(obx[3])\n",
    "                \n",
    "                # If OBX2 == (CW or CWE)\n",
    "                if (two == 'CW')|(two == 'CWE'):\n",
    "                    \n",
    "                    # Initialize parts\n",
    "                    pt1 = ''\n",
    "                    pt2 = ''\n",
    "                    pt3 = ''\n",
    "                    five = obx[5]\n",
    "                    \n",
    "                    # See if OBX-5.9 exists.  If so, re-define pt 1.\n",
    "                    if NoError(index_n,five,[0,8]):\n",
    "                        pt1 = str(index_n(five,[0,8]))\n",
    "                    \n",
    "                    # See if OBX-5.2 exists.  If so, re-define pt 2.\n",
    "                    if NoError(index_n,five,[0,1]):\n",
    "                        pt2 = str(index_n(five,[0,1]))\n",
    "                        \n",
    "                    # See if OBX-5.5 exists.  If so, re-define pt 3.\n",
    "                    if NoError(index_n,five,[0,4]):\n",
    "                        pt3 = str(index_n(five,[0,4]))\n",
    "                        \n",
    "                    # Define a concetated version (by '^' character) of OBX-5.9,OBX-5.2,OBX-5.5\n",
    "                    fife_dog = '^'.join([pt1,pt2,pt3])\n",
    "                    \n",
    "                    # If it isn't just a string of carrots...\n",
    "                    if len(fife_dog.replace('^',''))>0:\n",
    "                        \n",
    "                        # Append everything \n",
    "                        fives.append(fife_dog)\n",
    "                        twos.append(two)\n",
    "                        threes.append(three)\n",
    "                    \n",
    "                # If OBX2 == TX\n",
    "                elif (two == 'TX'):\n",
    "                    \n",
    "                    # Index 5...should work.\n",
    "                    five = obx[5]\n",
    "                    \n",
    "                    # Index OBX5 with a 0 until its a string.\n",
    "                    while type(five) != str:\n",
    "                        five = five[0]\n",
    "                        \n",
    "                    # Append all of them to the list 'fives'\n",
    "                    fives.append(five)\n",
    "                    twos.append(two)\n",
    "                    threes.append(three)\n",
    "\n",
    "    # After all repeated fields looped through concetate elements with '|' character\n",
    "    entry_5 = '|'.join(fives)\n",
    "    entry_2 = '|'.join(twos)\n",
    "    entry_3 = '|'.join(threes)\n",
    "    \n",
    "    # If we have non-zero length entry for OBX-5, append OBX2,OBX3, and OBX5 parts to respective dataframe locations.\n",
    "    if len(entry_5)>0:\n",
    "        df.loc[z,col_name] = entry_5\n",
    "        df.loc[z,col_name+'_OBX2'] = entry_2\n",
    "        df.loc[z,col_name+'_OBX3'] = entry_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C_FacType_Patient_Class\n",
    "--------------------\n",
    "Perform calculation based on another database variable.\n",
    "\n",
    "IF Facility_Type_Code is null then C_FacType_Patient_Class is null\n",
    "ELSE IF Facility_Type_Code=261QE0002X then C_FacType_Patient_Class=E\n",
    "ELSE IF Facility_Type_Code=1021-5 then C_FacType_Patient_Class=I\n",
    "ELSE IF Facility_Type_Code=261QM2500X then C_FacType_Patient_Class=O\n",
    "ELSE IF Facility_Type_Code=261QP2300X then C_FacType_Patient_Class=O\n",
    "ELSE IF Facility_Type_Code=261QU0200X then C_FacType_Patient_Class=O\n",
    "\n",
    " \\*Also outputs C_FacType_Patient_Class_Data_Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# How it looks  \n",
    "########################\n",
    "\n",
    "fac_code = str(df.loc[z,'Facility_Type_Code'])\n",
    "\n",
    "if fac_code == '261QE0002X':\n",
    "    df.loc[z,col_name] = 'E'\n",
    "elif fac_code == '1021-5':\n",
    "    df.loc[z,col_name] = 'I'\n",
    "elif (fac_code == '261QM2500X')|(fac_code == '261QP2300X')|(fac_code == '261QU0200X'):\n",
    "    df.loc[z,col_name] = 'O'\n",
    "    \n",
    "df.loc[z,col_name+'_Data_Source'] = 'Facility_Type_Code'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# Annotated Version  \n",
    "########################\n",
    "\n",
    "# Locate facility type code from our row (previously attained)\n",
    "fac_code = str(df.loc[z,'Facility_Type_Code'])\n",
    "\n",
    "# If it is code below, C_FacType_Patient_Class = 'E'\n",
    "if fac_code == '261QE0002X':\n",
    "    df.loc[z,col_name] = 'E'\n",
    "    \n",
    "# If it is code below, C_FacType_Patient_Class = 'E'\n",
    "elif fac_code == '1021-5':\n",
    "    df.loc[z,col_name] = 'I'\n",
    "    \n",
    "# If it is code below, C_FacType_Patient_Class = 'E'\n",
    "elif (fac_code == '261QM2500X')|(fac_code == '261QP2300X')|(fac_code == '261QU0200X'):\n",
    "    df.loc[z,col_name] = 'O'\n",
    "\n",
    "# All Data sources stem from Facility_Type_Code.  Assign this data_source in dataframe.\n",
    "df.loc[z,col_name+'_Data_Source'] = 'Facility_Type_Code'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C_Patient_Class\n",
    "--------------------\n",
    "Calculated patient class is set to: \n",
    "1) Patient_Class_Code (PV1-2) if it is non-null AND valid according to the PHIN standard (D, E, I, V, B, O, P, R)\n",
    "2) ELSE use a mapped Patient_Class_Code (PV1-2), if non-null AND not valid AND one of the following mapped values: \n",
    "    - Emergency: E \n",
    "    - Inpatient: I \n",
    "    - Observation: V\n",
    "     - EMER: E \n",
    "    - EMERGENCY: E\n",
    "    - INPATIENT: I\n",
    "    - HOS: I\n",
    "    - OBSERVE: V\n",
    "    - Emergency Department: E\n",
    "    - Outpatient: O\n",
    "    - ICU: I\n",
    "     - Obsv: V\n",
    "     - OUTPATIENT: O\n",
    "     - ER: E\n",
    "3) ELSE use C_FacType_Patient_Class\n",
    "4) ELSE assign class value based on the inferred patient class associated with the primary entry on the MFT (C_MFT_Patient_Class).  (Requires a look-up to the MFT table for the entry flagged as primary with Site_ID-C_Facility_ID; return the Inferred_Patient_Class value matching that entry)\n",
    "\n",
    " \\*Also outputs C_Patient_Class_Data_Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# How it looks \n",
    "########################\n",
    "\n",
    "#\n",
    "class_code = (df.loc[z,'Patient_Class_Code'])\n",
    "trigger = 0\n",
    "while trigger == 0:\n",
    "    if class_code ==  class_code:\n",
    "        class_code = str(class_code).upper()\n",
    "        if class_code in ['D', 'E', 'I', 'V', 'B', 'O', 'P', 'R']:\n",
    "            df.loc[z,col_name] = class_code\n",
    "            df.loc[z,col_name+'_Data_Source'] = 'Patient_Class_Code'\n",
    "            trigger = 1\n",
    "            break\n",
    "        else:\n",
    "            dicts1 = ['OBS','EMER','ER','INPATIENT','ICU','OUTPATIENT']\n",
    "            dicts2 = ['V','E','E','I','I','O']\n",
    "            for g in np.arange(0,len(dicts1)):\n",
    "                if dicts1[g] in class_code:\n",
    "                    df.loc[z,col_name] = dicts2[g]\n",
    "                    df.loc[z,col_name+'_Data_Source'] = 'Patient_Class_Code_Mapping'\n",
    "                    trigger = 1\n",
    "                    break\n",
    "    C_FacType_Patient_Class = (df.loc[z,'C_FacType_Patient_Class'])\n",
    "    if C_FacType_Patient_Class == C_FacType_Patient_Class:\n",
    "        df.loc[z,col_name] = C_FacType_Patient_Class\n",
    "        df.loc[z,col_name+'_Data_Source'] = 'C_FacType_Patient_Class'\n",
    "        trigger = 1\n",
    "    trigger = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# Annotated Version\n",
    "########################\n",
    "\n",
    "# Locate Patient_Class_Code from current row in dataframe (previously attained)\n",
    "class_code = (df.loc[z,'Patient_Class_Code'])\n",
    "\n",
    "# Initialize a trigger\n",
    "trigger = 0\n",
    "\n",
    "# Loop through until trigger is not 0\n",
    "while trigger == 0:\n",
    "    \n",
    "    # if class code is non-null...\n",
    "    if class_code ==  class_code:\n",
    "        \n",
    "        # Take uppercase letter if it isn't already uppercase\n",
    "        class_code = str(class_code).upper()\n",
    "        \n",
    "        # If it is one of these letters...\n",
    "        if class_code in ['D', 'E', 'I', 'V', 'B', 'O', 'P', 'R']:\n",
    "            \n",
    "            # Then C_Patient_Class = Patient_Class_Code.  \n",
    "            df.loc[z,col_name] = class_code\n",
    "            \n",
    "            # Record data source of 'Patient_Class_Code'\n",
    "            df.loc[z,col_name+'_Data_Source'] = 'Patient_Class_Code'\n",
    "            \n",
    "            # Put trigger = 0 / break loop\n",
    "            trigger = 1\n",
    "            break\n",
    "        \n",
    "        # Maybe Patient_Class_Code isn't one of those letters...now what?\n",
    "        else:\n",
    "            \n",
    "            # dicts1 are keywords\n",
    "            dicts1 = ['OBS','EMER','ER','INPATIENT','ICU','OUTPATIENT']\n",
    "            \n",
    "            # dicts2 has same length but indicates what letter dicts1 maps to\n",
    "            dicts2 = ['V','E','E','I','I','O']\n",
    "            \n",
    "            # Loop through dicts1\n",
    "            for g in np.arange(0,len(dicts1)):\n",
    "                \n",
    "                # If that keyword is somewhere in the Patient_Class_Code entry...\n",
    "                if dicts1[g] in class_code:\n",
    "                    \n",
    "                    # Then C_Patient_Class = dicts2[g] (what letter the keyword maps to)\n",
    "                    df.loc[z,col_name] = dicts2[g]\n",
    "                    \n",
    "                    # Record our data source\n",
    "                    df.loc[z,col_name+'_Data_Source'] = 'Patient_Class_Code_Mapping'\n",
    "                    \n",
    "                    # Set trigger / break to exit loop\n",
    "                    trigger = 1\n",
    "                    break\n",
    "                    \n",
    "    # Locate C_FacType_Patient_Class from current row in dataframe (previously attained)\n",
    "    C_FacType_Patient_Class = (df.loc[z,'C_FacType_Patient_Class'])\n",
    "    \n",
    "    # If it is non-null...\n",
    "    if C_FacType_Patient_Class == C_FacType_Patient_Class:\n",
    "        \n",
    "        # Then C_Patient_Class = C_FacType_Patient_Class\n",
    "        df.loc[z,col_name] = C_FacType_Patient_Class\n",
    "        \n",
    "        # Record data source\n",
    "        df.loc[z,col_name+'_Data_Source'] = 'C_FacType_Patient_Class'\n",
    "        \n",
    "        # Change trigger.  It will break.\n",
    "        trigger = 1\n",
    "        \n",
    "    # If nothing happened, change trigger. We can't find the element.  Cell will remain as np.NaN\n",
    "    trigger = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "### C_Death\n",
    "--------------------\n",
    "Set to \"Yes\" IF:\n",
    "* PID-30.1 (Patient_Death_Indicator) = First letter of \"Y\" and/or\n",
    "* PID-29.1 is not null and/or\n",
    "* PV1-36.1 contains \"20,\" \"22,\" \"23,\" \"24,\" \"25,\" \"26,\" \"27,\" \"28,\" \"29,\" \"40,\" \"41,\" or \"42\"\n",
    "\n",
    "ELSE set to \"No\"\n",
    "\n",
    " \\*Also outputs C_Death_Data_Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# How it looks\n",
    "########################\n",
    "\n",
    "trigger = 0\n",
    "while trigger == 0:\n",
    "    PDI = df.loc[z,'Patient_Death_Indicator']\n",
    "    if PDI == PDI:\n",
    "        if str(PDI)[0].upper() == 'Y':\n",
    "            df.loc[z,col_name] = 'Yes'\n",
    "            df.loc[z,col_name+'_Data_Source'] = 'Patient_Death_Indicator'\n",
    "            trigger = 1\n",
    "            break\n",
    "    Death_DT = df.loc[z,'Patient_Death_DateTime']\n",
    "    if Death_DT == Death_DT:\n",
    "        df.loc[z,col_name] = 'Yes'\n",
    "        df.loc[z,col_name+'_Data_Source'] = 'Patient_Death_DateTime'\n",
    "        trigger = 1\n",
    "        break\n",
    "    Dis_Disp = df.loc[z,'Discharge_Disposition']\n",
    "    if Dis_Disp == Dis_Disp:\n",
    "        dead_keys = ['20','22','23','24','25','26','27','28','29','40','41','42']\n",
    "        for g in np.arange(0,len(dead_keys)):\n",
    "            if dead_keys[g] in str(Dis_Disp):\n",
    "                df.loc[z,col_name] = 'Yes'\n",
    "                df.loc[z,col_name+'_Data_Source'] = 'Discharge_Disposition'\n",
    "                break       \n",
    "    if trigger == 0:\n",
    "        df.loc[z,col_name] = 'No'\n",
    "        trigger = 1\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# Annotated Version\n",
    "########################\n",
    "\n",
    "# Initialize trigger\n",
    "trigger = 0\n",
    "\n",
    "# Loop\n",
    "while trigger == 0:\n",
    "    \n",
    "    # Locate PDI from dataframe row (already solved for)\n",
    "    PDI = df.loc[z,'Patient_Death_Indicator']\n",
    "    \n",
    "    # If it is non-null\n",
    "    if PDI == PDI:\n",
    "        \n",
    "        # See if the first letter in uppercase is Y\n",
    "        if str(PDI)[0].upper() == 'Y':\n",
    "            \n",
    "            # If so, C_Death = 'Yes'\n",
    "            df.loc[z,col_name] = 'Yes'\n",
    "            \n",
    "            # Record Data source and break loop\n",
    "            df.loc[z,col_name+'_Data_Source'] = 'Patient_Death_Indicator'\n",
    "            trigger = 1\n",
    "            break\n",
    "            \n",
    "    # Locate Death_DT from dataframe row (already solved for)\n",
    "    Death_DT = df.loc[z,'Patient_Death_DateTime']\n",
    "    \n",
    "    # If it is non-null...\n",
    "    if Death_DT == Death_DT:\n",
    "        \n",
    "        # Then C_Death = 'Yes'\n",
    "        df.loc[z,col_name] = 'Yes'\n",
    "        \n",
    "        # Record Data Source and break loop\n",
    "        df.loc[z,col_name+'_Data_Source'] = 'Patient_Death_DateTime'\n",
    "        trigger = 1\n",
    "        break\n",
    "        \n",
    "    # Locate Dicharge Disp from dataframe row (already solved for)\n",
    "    Dis_Disp = df.loc[z,'Discharge_Disposition']\n",
    "    \n",
    "    # If it is non-null...\n",
    "    if Dis_Disp == Dis_Disp:\n",
    "        \n",
    "        # Define discharge disposition keys that indicate death\n",
    "        dead_keys = ['20','22','23','24','25','26','27','28','29','40','41','42']\n",
    "        \n",
    "        # Loop through dead keys\n",
    "        for g in np.arange(0,len(dead_keys)):\n",
    "            \n",
    "            # If the dichage disposition contains this key, the patient died\n",
    "            if dead_keys[g] in str(Dis_Disp):\n",
    "                \n",
    "                # Then C_Death = 'Yes'\n",
    "                df.loc[z,col_name] = 'Yes'\n",
    "                \n",
    "                # Record Data Source and break the loop\n",
    "                df.loc[z,col_name+'_Data_Source'] = 'Discharge_Disposition'\n",
    "                break      \n",
    "                \n",
    "    #If we made it this far and the trigger is still 0...\n",
    "    if trigger == 0:\n",
    "        \n",
    "        # Then the patient didn't die!\n",
    "        \n",
    "        # Record 'No'.  Since we didn't really use a data source, don't record one\n",
    "        df.loc[z,col_name] = 'No'\n",
    "        \n",
    "        # Change trigger and break.\n",
    "        trigger = 1\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medical_Record_Number\n",
    "--------------------\n",
    "Direct input from HL7 message, select the FIRST non-null PID-3.1 value \n",
    "WHERE\n",
    "PID-3.5 = \"MR\" (Medical Record Number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# How it looks\n",
    "########################\n",
    "\n",
    "pid35 = Index_pull(['PID',0,3,0,4,0],m)\n",
    "if pid35 == 'MR':\n",
    "    ind = ['PID',0,3,0,0]\n",
    "    DI_One(ind,m,df,z,col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# Annotated Version\n",
    "########################\n",
    "\n",
    "# Locate/define PID-3.5\n",
    "pid35 = Index_pull(['PID',0,3,0,4,0],m)\n",
    "\n",
    "# If the PID-3.5 == 'MR'\n",
    "if pid35 == 'MR':\n",
    "    \n",
    "    # Define indeces for PID-3.1\n",
    "    ind = ['PID',0,3,0,0]\n",
    "    \n",
    "    # Use DI_One() function to append info to our array\n",
    "    DI_One(ind,m,df,z,col_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age_Reported\n",
    "--------------------\n",
    "OBX-5 segment where OBX-3 observation identifier of 21612-7 AGE-REPORTED (LOINC) and OBX-2 Value Type=\"NM\"\n",
    "\n",
    "NOTE: If the Age Reported measurement reported does not \"fit\" into the decimal(6,2) datatype, the measurement will not be stored in Age_Reported. The string value of the measurement will still be stored in Str_Age_Reported.\n",
    "\n",
    " \\*Also outputs Age_Reported_OBX2\n",
    "\n",
    "\\*Also outputs Age_Reported_OBX3\n",
    "\n",
    "\n",
    "# Important Note:\n",
    "\n",
    "When I tested my code on over 1,000 sample PHESS data rows, none of them fit into the decimal(6,2) datatype.  An example of this datatype would be 0025.00 for the age of 25.  Again, I could not find any cases where I saw this.  \n",
    "\n",
    "My decision is to instead list off the integer value in OBX-5.  Just using intuition.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# How it looks\n",
    "########################\n",
    "\n",
    "if NoError(index,m,'OBX'):\n",
    "    five = ''\n",
    "    obxs = m['OBX']\n",
    "    pat = '21612-7'\n",
    "    pattern = re.compile(pat,re.M|re.I)\n",
    "    for q in np.arange(0,len(obxs)):\n",
    "        obx = obxs[q]\n",
    "        searchme = str(obx)\n",
    "        match = re.findall(pattern,searchme)\n",
    "        num_matches = len(match)\n",
    "        if num_matches > 0:\n",
    "            units = ''\n",
    "            two = str(obx[2])\n",
    "            three = str(obx[3])\n",
    "            five = obx[5]\n",
    "            if str(two).upper() == 'NM':\n",
    "                while type(five) != str:\n",
    "                    five = five[0]\n",
    "            units = Index_pull([6,0,1],obx)\n",
    "            if len(five)>0:\n",
    "                df.loc[z,col_name] = five\n",
    "                df.loc[z,col_name+'_OBX2'] = two\n",
    "                df.loc[z,col_name+'_OBX3'] = three\n",
    "                \n",
    "                df.loc[z,'Age_Units_Reported'] = units\n",
    "                df.loc[z,'Age_Units_Reported_OBX2'] = two\n",
    "                df.loc[z,'Age_Units_Reported_OBX3'] = three\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# Annotated Version\n",
    "########################\n",
    "\n",
    "# See if message has an 'OBX' field\n",
    "if NoError(index,m,'OBX'):\n",
    "    \n",
    "    # Initialize OBX5\n",
    "    five = ''\n",
    "    \n",
    "    # Call OBX repeated fields 'obxs'\n",
    "    obxs = m['OBX']\n",
    "    \n",
    "    # Define and compile the keyword pattern in RegEx\n",
    "    pat = '21612-7'\n",
    "    pattern = re.compile(pat,re.M|re.I)\n",
    "    \n",
    "    # Loop through OBX fields\n",
    "    for q in np.arange(0,len(obxs)):\n",
    "        \n",
    "        # Define current obx field as 'obx' and a string version as 'searchme'\n",
    "        obx = obxs[q]\n",
    "        searchme = str(obx)\n",
    "        \n",
    "        # Use RegEx to look for matches\n",
    "        match = re.findall(pattern,searchme)\n",
    "        num_matches = len(match)\n",
    "        \n",
    "        # If the number of keyword matches is non-zero...\n",
    "        if num_matches > 0:\n",
    "            \n",
    "            # Initialize units\n",
    "            units = ''\n",
    "            \n",
    "            # Locate OBX2,3,5\n",
    "            two = str(obx[2])\n",
    "            three = str(obx[3])\n",
    "            five = obx[5]\n",
    "            \n",
    "            # If OBX-2 reflects numeric datatype...\n",
    "            if str(two).upper() == 'NM':\n",
    "                \n",
    "                # Index OBX-5 by 0 until it is a string\n",
    "                while type(five) != str:\n",
    "                    five = five[0]\n",
    "            \n",
    "            # Pull out units (OBX-6.2)\n",
    "            units = Index_pull([6,0,1],obx)\n",
    "            \n",
    "            # If we have an non-zero length age...\n",
    "            if len(five)>0:\n",
    "                \n",
    "                # Append OBX-5,2,3 into our dataframe in the Age_Reported related cells\n",
    "                df.loc[z,col_name] = five\n",
    "                df.loc[z,col_name+'_OBX2'] = two\n",
    "                df.loc[z,col_name+'_OBX3'] = three\n",
    "                \n",
    "                # Append OBX-5,2,3 into our dataframe in the Age_Units_Reported related cells\n",
    "                df.loc[z,'Age_Units_Reported'] = units\n",
    "                df.loc[z,'Age_Units_Reported_OBX2'] = two\n",
    "                df.loc[z,'Age_Units_Reported_OBX3'] = three"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C_Patient_County\n",
    "--------------------\n",
    "Return the first non-null value from:\n",
    "* PID-11.9\n",
    "* PID-12.1\n",
    "\n",
    " \\*Also outputs C_Patient_County_Data_Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# How it looks\n",
    "########################\n",
    "\n",
    "pid119 = Index_pull(['PID',0,11,0,8],m)\n",
    "\n",
    "if len(pid119) > 0:\n",
    "    df.loc[z,col_name] = pid119\n",
    "    df.loc[z,col_name+'_Data_Source'] = 'County_Code'\n",
    "\n",
    "else:\n",
    "    pid121 = Index_pull(['PID',0,12,0,0],m)\n",
    "    if len(pid121) > 0:\n",
    "        df.loc[z,col_name] = pid119\n",
    "        df.loc[z,col_name+'_Data_Source'] = 'PID-12.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# Annotated Version\n",
    "########################\n",
    "\n",
    "# Look at PID-11.9 WITHOUT actually appending it to a dataframe\n",
    "pid119 = Index_pull(['PID',0,11,0,8],m)\n",
    "\n",
    "# If PID-11.9 has non-zero length...\n",
    "if len(pid119) > 0:\n",
    "    \n",
    "    # then C_Patient_County = PID-11.9\n",
    "    df.loc[z,col_name] = pid119\n",
    "    \n",
    "    # Record Data Source\n",
    "    df.loc[z,col_name+'_Data_Source'] = 'County_Code'\n",
    "\n",
    "# Otherwise...\n",
    "else:\n",
    "    \n",
    "    # Look at PID-12.1 WITHOUT actually appending it to a dataframe\n",
    "    pid121 = Index_pull(['PID',0,12,0,0],m)\n",
    "    \n",
    "    # If PID-12.1 has non-zero length...\n",
    "    if len(pid121) > 0:\n",
    "        \n",
    "        # then C_Patient_County = PID-12.1\n",
    "        df.loc[z,col_name] = pid119\n",
    "        \n",
    "        # Record Data Source\n",
    "        df.loc[z,col_name+'_Data_Source'] = 'PID-12.1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C_Patient_Age\n",
    "--------------------\n",
    "Select the first non-null value from:\n",
    "* C_Visit_Date - Birth_Date**\n",
    "* Age_Reported \n",
    "* Age_Calculated \n",
    "\n",
    "** when performing the calculation, store the numeric year value if the value >= 2 years (round down to the nearest integer); else, store the number of months and round down to the nearest integer (i.e., 4.9 rounds to 4; 5.2 rounds to 5). If the number resolved is greater than 150 years, the Birth_Date_Time column will be set to NULL and the calculation will continue down the hierarchy to Age_Reported or Age_Calculated. If the value resolved is less than 1 month, store 0. \n",
    "Otherwise, we use the age and companion units from the message as hierarchically defined.\n",
    "\n",
    " \\*Also outputs C_Patient_Age_Data_Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# How it looks\n",
    "########################\n",
    "\n",
    "\n",
    "c_visit_date = df.loc[z,'C_Visit_Date']\n",
    "birth = df.loc[z,'Birth_Date_Time']\n",
    "\n",
    "\n",
    "if (c_visit_date == c_visit_date)&(birth == birth):\n",
    "    c_visit_date = pd.to_datetime(c_visit_date[:8])\n",
    "    birth = pd.to_datetime(birth[:8])\n",
    "    years = int((c_visit_date - birth).days / 365.25)\n",
    "    if years<2:\n",
    "        df.loc[z,col_name] = int((c_visit_date - birth).days / (30.4375))\n",
    "        df.loc[z,col_name+'_Data_Source'] = 'C_Visit_Date - Birth_Date'\n",
    "        df.loc[z,'C_Patient_Age_Units'] = 'Months'\n",
    "        df.loc[z,'C_Patient_Age_Units_Data_Source'] = 'C_Visit_Date - Birth_Date'\n",
    "    elif (years>=2)&(years<150):\n",
    "        df.loc[z,col_name] = years\n",
    "        df.loc[z,col_name+'_Data_Source'] = 'C_Visit_Date - Birth_Date'\n",
    "        df.loc[z,'C_Patient_Age_Units'] = 'Years'\n",
    "        df.loc[z,'C_Patient_Age_Units_Data_Source'] = 'C_Visit_Date - Birth_Date'\n",
    "        \n",
    "else:\n",
    "    age_reported = df.loc[z,'Age_Reported']\n",
    "    age_units_reported = df.loc[z,'Age_Units_Reported']\n",
    "    \n",
    "    if (age_reported == age_reported)&(age_units_reported == age_units_reported):\n",
    "        df.loc[z,col_name] = age_reported\n",
    "        df.loc[z,col_name+'_Data_Source'] = 'Age_Reported'\n",
    "        df.loc[z,'C_Patient_Age_Units'] = age_units_reported\n",
    "        df.loc[z,'C_Patient_Age_Units_Data_Source'] = 'Age_Units_Reported'\n",
    "        \n",
    "    else:\n",
    "        cal_age = df.loc[z,'Age_Calculated']\n",
    "    \n",
    "        if (cal_age == cal_age):\n",
    "            df.loc[z,col_name] = cal_age\n",
    "            df.loc[z,col_name+'_Data_Source'] = 'Age_Calculated'\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# Annotated Version\n",
    "########################\n",
    "\n",
    "# Locate our C_Visit_Date and Birth_Date_Time\n",
    "c_visit_date = df.loc[z,'C_Visit_Date']\n",
    "birth = df.loc[z,'Birth_Date_Time']\n",
    "\n",
    "# If both of these are non-null...\n",
    "if (c_visit_date == c_visit_date)&(birth == birth):\n",
    "    \n",
    "    # Only take the YYYYMMDD values of these anc convert to datetime\n",
    "    c_visit_date = pd.to_datetime(c_visit_date[:8])\n",
    "    birth = pd.to_datetime(birth[:8])\n",
    "    \n",
    "    # Take the difference between the two datetimes in days, divide by days in a year, and round down to integer\n",
    "    years = int((c_visit_date - birth).days / 365.25)\n",
    "    \n",
    "    # If they're less than 2 years old\n",
    "    if years<2:\n",
    "        \n",
    "        # Then C_Patient_Age should be age in months...calculate this similarly to years, but divide by days in an avg month\n",
    "        df.loc[z,col_name] = int((c_visit_date - birth).days / (30.4375))\n",
    "        \n",
    "        # Record Data Source\n",
    "        df.loc[z,col_name+'_Data_Source'] = 'C_Visit_Date - Birth_Date'\n",
    "        \n",
    "        # Record Age units as months and record that Data Source\n",
    "        df.loc[z,'C_Patient_Age_Units'] = 'Months'\n",
    "        df.loc[z,'C_Patient_Age_Units_Data_Source'] = 'C_Visit_Date - Birth_Date'\n",
    "        \n",
    "    # If they are older than 2 and less than 150 years old...\n",
    "    elif (years>=2)&(years<150):\n",
    "        \n",
    "        # record age, data source, age units, age units data source\n",
    "        df.loc[z,col_name] = years\n",
    "        df.loc[z,col_name+'_Data_Source'] = 'C_Visit_Date - Birth_Date'\n",
    "        df.loc[z,'C_Patient_Age_Units'] = 'Years'\n",
    "        df.loc[z,'C_Patient_Age_Units_Data_Source'] = 'C_Visit_Date - Birth_Date'\n",
    "\n",
    "# At least one of the two values was null...\n",
    "else:\n",
    "    # Find age_reported and age_units_reported\n",
    "    age_reported = df.loc[z,'Age_Reported']\n",
    "    age_units_reported = df.loc[z,'Age_Units_Reported']\n",
    "    \n",
    "    # If both of these are non-null\n",
    "    if (age_reported == age_reported)&(age_units_reported == age_units_reported):\n",
    "        \n",
    "        # Then C_Patient_Age = Age_Reported.  Document this data source\n",
    "        df.loc[z,col_name] = age_reported\n",
    "        df.loc[z,col_name+'_Data_Source'] = 'Age_Reported'\n",
    "        \n",
    "        # Then C_Patient_Age_Units = Age_Units_Reported.  Document this data source\n",
    "        df.loc[z,'C_Patient_Age_Units'] = age_units_reported\n",
    "        df.loc[z,'C_Patient_Age_Units_Data_Source'] = 'Age_Units_Reported'\n",
    "        \n",
    "    # Now either age_reported or age_units_reported was null...\n",
    "    else:\n",
    "        \n",
    "        # Locate Age_Calculated in our dataframe row\n",
    "        cal_age = df.loc[z,'Age_Calculated']\n",
    "        \n",
    "        # If it is non-null...\n",
    "        if (cal_age == cal_age):\n",
    "            \n",
    "            # Then C_Patient_Age = Age_Calculated.  Record data sourec.\n",
    "            df.loc[z,col_name] = cal_age\n",
    "            df.loc[z,col_name+'_Data_Source'] = 'Age_Calculated'\n",
    "    \n",
    "    # If nothing works, we cannot find it and C_Patient_Age will be np.NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age Calculated\n",
    "\n",
    "OBX-5 segment where OBX-3 segment ID '29553-5'\n",
    "\n",
    "NOTE: If the Age Calculated measurement reported does not \"fit\" into the decimal(6,2) datatype, the measurement will not be stored in Age_Calculated. The string value of the measurement will still be stored in Str_Age_Calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# How it looks\n",
    "########################\n",
    "\n",
    "if NoError(index,m,'OBX'):\n",
    "    five = ''\n",
    "    obxs = m['OBX']\n",
    "    pat = '29553-5'\n",
    "    pattern = re.compile(pat,re.M|re.I)\n",
    "    for q in np.arange(0,len(obxs)):\n",
    "        obx = obxs[q]\n",
    "        searchme = str(obx)\n",
    "        match = re.findall(pattern,searchme)\n",
    "        num_matches = len(match)\n",
    "        if num_matches > 0:\n",
    "            five = obx[5]\n",
    "            while type(five) != str:\n",
    "                five = five[0]\n",
    "            if len(five)>0:\n",
    "                df.loc[z,col_name] = five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# Annotated Version\n",
    "########################\n",
    "\n",
    "# See if message has an OBX field\n",
    "if NoError(index,m,'OBX'):\n",
    "\n",
    "    # Initialize OBX-5\n",
    "    five = ''\n",
    "    \n",
    "    # Call list of OBX fields 'obxs'\n",
    "    obxs = m['OBX']\n",
    "    \n",
    "    # Define the pattern we are looking for and compile it using RegEx\n",
    "    pat = '29553-5'\n",
    "    pattern = re.compile(pat,re.M|re.I)\n",
    "    \n",
    "    # Loop through all the 'OBX' fields.\n",
    "    for q in np.arange(0,len(obxs)):\n",
    "        \n",
    "        # Define the 'OBX' field we are looking at and keep a string copy as 'searchme'\n",
    "        obx = obxs[q]\n",
    "        searchme = str(obx)\n",
    "        \n",
    "        # Check for matches using RegEx\n",
    "        match = re.findall(pattern,searchme)\n",
    "        num_matches = len(match)\n",
    "        \n",
    "        #If there are matches\n",
    "        if num_matches > 0:\n",
    "            \n",
    "            # Index OBX-5\n",
    "            five = obx[5]\n",
    "            \n",
    "            # Index with a 0 until it is a string\n",
    "            while type(five) != str:\n",
    "                five = five[0]\n",
    "                \n",
    "            # If we found something with non-zero length then we've found it!  Append to our dataframe.\n",
    "            if len(five)>0:\n",
    "                df.loc[z,col_name] = five"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C_Chief_Complaint\n",
    "--------------------\n",
    "Hierarchically defined (select first non-null):\n",
    "* Chief_Complaint_Text\n",
    "* Admit_Reason_Description\n",
    "\n",
    " \\*Also outputs C_Chief_Complaint_Data_Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# How it looks\n",
    "########################\n",
    "\n",
    "Chief_Complaint_Text = df.loc[z,'Chief_Complaint_Text']\n",
    "\n",
    "if (Chief_Complaint_Text==Chief_Complaint_Text):\n",
    "    df.loc[z,col_name] = Chief_Complaint_Text\n",
    "    df.loc[z,col_name+'_Data_Source'] = 'Chief_Complaint_Text'\n",
    "    \n",
    "else:\n",
    "    Admit_Reason_Description = df.loc[z,'Admit_Reason_Description']\n",
    "    if (Admit_Reason_Description==Admit_Reason_Description):\n",
    "        df.loc[z,col_name] = Admit_Reason_Description\n",
    "        df.loc[z,col_name+'_Data_Source'] = 'Admit_Reason_Description'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# Annotated Version\n",
    "########################\n",
    "\n",
    "# Locate Chief_Complaint_Text from our dataframe row\n",
    "Chief_Complaint_Text = df.loc[z,'Chief_Complaint_Text']\n",
    "\n",
    "# If it is non-null...\n",
    "if (Chief_Complaint_Text==Chief_Complaint_Text):\n",
    "    \n",
    "    #  Then C_Chief_Complaint = Chief_Complaint_Text.  Record data source\n",
    "    df.loc[z,col_name] = Chief_Complaint_Text\n",
    "    df.loc[z,col_name+'_Data_Source'] = 'Chief_Complaint_Text'\n",
    "    \n",
    "# Otherwise (it was null)\n",
    "else:\n",
    "    \n",
    "    # Locate Admit_Reason_Description from our dataframe row\n",
    "    Admit_Reason_Description = df.loc[z,'Admit_Reason_Description']\n",
    "    \n",
    "    # If it is non-null...\n",
    "    if (Admit_Reason_Description==Admit_Reason_Description):\n",
    "        \n",
    "        #  Then C_Chief_Complaint = Admit_Reason_Description.  Record data source\n",
    "        df.loc[z,col_name] = Admit_Reason_Description\n",
    "        df.loc[z,col_name+'_Data_Source'] = 'Admit_Reason_Description'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chief_Complaint_Code\n",
    "--------------------\n",
    "OBX-5.1, OBX-5.4 segments where:\n",
    "* OBX-3 Observation Identifier is 8661-1 and/or 11292-0\n",
    "* OBX-2 = \"CWE\" or \"CW\"\n",
    "\n",
    "Select first non-null value from segments OBX-5.1, OBX-5.4 and concatenate if repeating\n",
    "\n",
    " \\*Also outputs Chief_Complaint_Code_OBX2\n",
    "\n",
    "\\*Also outputs Chief_Complaint_Code_OBX3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTANT NOTE - \n",
    "\n",
    "Reading the description above, we see that there is a chance that we will have multiple chief complaint code fields.  If this is the case, we will have to concatenate the multiple fields.  We will denote this field concetation with the '|' character.\n",
    "\n",
    "There is also a chance that we will have to concatenate multiple subcomponents.  We will denote this sub-concetation with a '^' character.\n",
    "\n",
    "While it is rare for the Chief Complaint Code field to repeat, there is a chance that we will end up with a chief_complaint_code similar to the example below.\n",
    "\n",
    "`CC_Code = OBX.1.5.1^OBX.1.5.4| OBX.4.5.1^OBX.4.5.4\n",
    "\n",
    "Above the repeating field is OBX|1| and OBX|4|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# How it looks\n",
    "########################\n",
    "\n",
    "pat = '(8661-1)|(11292-0)'\n",
    "pattern = re.compile(pat,re.M|re.I)\n",
    "two = ''\n",
    "three = ''\n",
    "five = ''\n",
    "\n",
    "\n",
    "fives = []\n",
    "twos = []\n",
    "threes = []\n",
    "if NoError(index,m,'OBX'):\n",
    "    sect = index(m,'OBX')\n",
    "    for j in np.arange(0,len(sect)):\n",
    "        obx = sect[j]\n",
    "        searchme = str(obx)\n",
    "        match = re.findall(pattern,searchme)\n",
    "        two = ''\n",
    "        three = ''\n",
    "        five = ''\n",
    "        if len(match):\n",
    "            if NoError(index,obx,2) & NoError(index,obx,3) & NoError(index,obx,5):\n",
    "                two = str(obx[2])\n",
    "                three = str(obx[3])\n",
    "                if (two == 'CW')|(two == 'CWE'):\n",
    "                    pt1 = ''\n",
    "                    pt2 = ''\n",
    "                    five = obx[5]\n",
    "                    \n",
    "                    if NoError(index_n,five,[0,0]):\n",
    "                        pt1 = str(index_n(five,[0,0]))\n",
    "                    if NoError(index_n,five,[0,3]):\n",
    "                        pt2 = str(index_n(five,[0,3]))\n",
    "                        \n",
    "                    fife_dog = '^'.join([pt1,pt2])\n",
    "                    if len(fife_dog.replace('^',''))>0:\n",
    "                        fives.append(fife_dog)\n",
    "                        twos.append(two)\n",
    "                        threes.append(three)\n",
    "\n",
    "    entry_5 = '|'.join(fives)\n",
    "    entry_2 = '|'.join(twos)\n",
    "    entry_3 = '|'.join(threes)\n",
    "    \n",
    "    if len(entry_5)>0:\n",
    "        df.loc[z,col_name] = entry_5\n",
    "        df.loc[z,col_name+'_OBX2'] = entry_2\n",
    "        df.loc[z,col_name+'_OBX3'] = entry_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# Annotated Version\n",
    "########################\n",
    "\n",
    "# Identify the pattern(s) we will look for and compile in RegEx\n",
    "pat = '(8661-1)|(11292-0)'\n",
    "pattern = re.compile(pat,re.M|re.I)\n",
    "\n",
    "# Create empty array for concentated elements to be appended to.  Later merged into 1 string\n",
    "fives = []\n",
    "twos = []\n",
    "threes = []\n",
    "\n",
    "# Check to see if OBX can be indexed into\n",
    "if NoError(index,m,'OBX'):\n",
    "    \n",
    "    # If so, define obx field as 'sect'\n",
    "    sect = index(m,'OBX')\n",
    "    \n",
    "    #  Loop through repeated OBX fields\n",
    "    for j in np.arange(0,len(sect)):\n",
    "        \n",
    "        # Define obx field in question as 'obx' and create string copy of it called 'searchme'\n",
    "        obx = sect[j]\n",
    "        searchme = str(obx)\n",
    "        \n",
    "        # Search for RegEx keyword matches within obx string\n",
    "        match = re.findall(pattern,searchme)\n",
    "        \n",
    "        # Initialize OBX2,3,5\n",
    "        two = ''\n",
    "        three = ''\n",
    "        five = ''\n",
    "        \n",
    "        # If we have any matches....\n",
    "        if len(match):\n",
    "            \n",
    "            # Check to see if OBX2,OBX3,and OBX5 exist\n",
    "            if NoError(index,obx,2) & NoError(index,obx,3) & NoError(index,obx,5):\n",
    "                \n",
    "                # Define OBX2,3\n",
    "                two = str(obx[2])\n",
    "                three = str(obx[3])\n",
    "                \n",
    "                # If OBX2 == (CW or CWE)\n",
    "                if (two == 'CW')|(two == 'CWE'):\n",
    "                    \n",
    "                    # Initialize parts\n",
    "                    pt1 = ''\n",
    "                    pt2 = ''\n",
    "                    five = obx[5]\n",
    "                    \n",
    "                    # See if OBX-5.1 exists.  If so, re-define pt 1.\n",
    "                    if NoError(index_n,five,[0,0]):\n",
    "                        pt1 = str(index_n(five,[0,0]))\n",
    "                        \n",
    "                    # See if OBX-5.4 exists.  If so, re-define pt 1.\n",
    "                    if NoError(index_n,five,[0,3]):\n",
    "                        pt2 = str(index_n(five,[0,3]))\n",
    "                        \n",
    "                    # Created a concetated version (by '^' character) of OBX-5.1,OBX-5.4\n",
    "                    fife_dog = '^'.join([pt1,pt2])\n",
    "                    \n",
    "                    # If it is not just one '^' character, append it to fives, append two,three\n",
    "                    if len(fife_dog.replace('^',''))>0:\n",
    "                        fives.append(fife_dog)\n",
    "                        twos.append(two)\n",
    "                        threes.append(three)\n",
    "    \n",
    "    # Join concetated element entries by '|' character into one string\n",
    "    entry_5 = '|'.join(fives)\n",
    "    entry_2 = '|'.join(twos)\n",
    "    entry_3 = '|'.join(threes)\n",
    "    \n",
    "    #If we have a non-zero length entry_5 element...add OBX-5,2,3 to dataframe\n",
    "    if len(entry_5)>0:\n",
    "        df.loc[z,col_name] = entry_5\n",
    "        df.loc[z,col_name+'_OBX2'] = entry_2\n",
    "        df.loc[z,col_name+'_OBX3'] = entry_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C_Patient_Age_Years\n",
    "--------------------\n",
    "Resolve the value returned in C_Patient_Age into a normalized Years value. The age of the patient should round down to the nearest Integer.\n",
    "\n",
    "* If C_Patient_Age_Units begins with an M we will divide that value by 12 and round down.\n",
    "* If C_Patient_Age_Units begins with a W we will divide that value by 52 and round down.\n",
    "* If C_Patient_Age_Units begins with a D we will divide that value by 365 and round down.\n",
    "* If C_Patient_Age_Units begins with a Y or ANNUM we will round down to the nearest whole number.\n",
    "\n",
    "NOTE: The age calculation does not account for leap years at this time. This means the C_Patient_Age may be incorrect for patients with close birth dates and visit dates.\n",
    "\n",
    " \\*Also outputs C_Patient_Age_Years_Data_Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# How it looks\n",
    "########################\n",
    "\n",
    "C_Patient_Age = df.loc[z,'C_Patient_Age']\n",
    "sources = 'C_Patient_Age, C_Patient_Age_Units'\n",
    "\n",
    "if (C_Patient_Age == C_Patient_Age):\n",
    "    C_Patient_Age_Units = df.loc[z,'C_Patient_Age_Units']\n",
    "    if str(C_Patient_Age_Units).upper() = 'Y':\n",
    "        df.loc[z,col_name] = C_Patient_Age\n",
    "        df.loc[z,col_name+'_Data_Source'] = sources\n",
    "    elif str(C_Patient_Age_Units).upper() = 'M':\n",
    "        df.loc[z,col_name] = int(int(C_Patient_Age)/12)\n",
    "        df.loc[z,col_name+'_Data_Source'] = sources\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# Annotated Code\n",
    "########################\n",
    "\n",
    "# Locate C_Patient_Age from our dataframe row\n",
    "C_Patient_Age = df.loc[z,'C_Patient_Age']\n",
    "\n",
    "# Pre-record the source to later add to data_source dataframe cell\n",
    "sources = 'C_Patient_Age, C_Patient_Age_Units'\n",
    "\n",
    "# If C_Patient_Age is non-null...\n",
    "if (C_Patient_Age == C_Patient_Age):\n",
    "    \n",
    "    # Then locate the associated units in our dataframe row\n",
    "    C_Patient_Age_Units = df.loc[z,'C_Patient_Age_Units']\n",
    "    \n",
    "    # If the units value begins with 'Y'...\n",
    "    if str(C_Patient_Age_Units).upper() = 'Y':\n",
    "        \n",
    "        # This means that the age is already in years.  Write to dataframe.  Record source.\n",
    "        df.loc[z,col_name] = C_Patient_Age\n",
    "        df.loc[z,col_name+'_Data_Source'] = sources\n",
    "        \n",
    "    # Elif the units value begins with 'M'...\n",
    "    elif str(C_Patient_Age_Units).upper() = 'M':\n",
    "        \n",
    "        # This means that the age is in Months.  Divide by 12 and round down to int for age in years. Record data source.\n",
    "        df.loc[z,col_name] = int(int(C_Patient_Age)/12)\n",
    "        df.loc[z,col_name+'_Data_Source'] = sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The supporting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pj_funcs import *\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "def NoError(func, *args, **kw):\n",
    "    '''\n",
    "    Determine whether or not a function and its arguments gives an error\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    func: function, required\n",
    "    *args: varies, required\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True if function does not cause error.\n",
    "\tFalse if function causes error.\n",
    "        \n",
    "    Requirements\n",
    "    ------------\n",
    "    -none\n",
    "    '''\n",
    "    try:\n",
    "        func(*args, **kw)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "    \n",
    "    \n",
    "############################################################################################################\n",
    "\n",
    "def index_n(m,ind):\n",
    "    '''\n",
    "    Indexes some object 'm' by each element in the list 'ind'\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    m: type varies, required\n",
    "    ind: list, required\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    m[ind[0]][ind[1]][ind[...]][ind[n]]\n",
    "     \n",
    "    Requirements\n",
    "    ------------\n",
    "    -Numpy as np\n",
    "    \n",
    "    '''\n",
    "    for i in np.arange(0,len(ind)):\n",
    "        m = m[ind[i]]\n",
    "    return m\n",
    "\n",
    "#############################################################################################################\n",
    "\n",
    "def Index_pull(ind,m):\n",
    "    \n",
    "    '''\n",
    "    Locates and returns the element within a message 'm' thats location\n",
    "        is described by indeces, 'ind'\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ind: list, required, full index path as list indicating HL7 location.\n",
    "    m: hl7 type object, required, m = hl7.parse(some_message)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Str\n",
    "        Element\n",
    "     \n",
    "    Requirements\n",
    "    ------------\n",
    "    -NoError from pj_funcs.py\n",
    "    -index_n from pj_funcs.py\n",
    "    -hl7\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    output = ''\n",
    "    \n",
    "    # Try indexing the message by ind\n",
    "    if NoError(index_n,m,ind):\n",
    "        \n",
    "        #  If the indexing up to the 2nd to last element returns a string, accept it.  Call it 'output'\n",
    "        if type(index_n(m,ind[:-1])) == str:\n",
    "            output = index_n(m,ind[:-1])\n",
    "\n",
    "        # Normally, we will take the exact, full-indexed value.  Call it 'output'\n",
    "        else:\n",
    "            output = str(index_n(m,ind))\n",
    "    \n",
    "    # Return output.  If none found, return empty string, ''\n",
    "    return output\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "def Index_pull_CONC(field,rest_index,m):\n",
    "    '''\n",
    "    Returns a concetated string for elements with repeating fields. Seperated by '|' characters.\n",
    "    \n",
    "    Example: consider the case of Ethnicity Code where a patient may have multiple selected ethnicities.\n",
    "        For our example we will assume this element is always located in PID-22.1.\n",
    "    \n",
    "            print(Index_pull_CONC('PID', [22,0,0], m))\n",
    "                Ethnicity1|Ethnicity2\n",
    "        \n",
    "        Note:  Ethnicity1 and Ethnicity2 are pulled from PID|x|-22.1 and PID|y|-22.1 respectively where\n",
    "            x,y are non-equal integers representing different repetitions of a repeated field.\n",
    "        \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    field: list (with one element), required, for non-empty return choose valid 3 letter HL7 field\n",
    "    rest: list, required, integer list indicating where to find it.\n",
    "    m: hl7 type object, required, m = hl7.parse(some_message)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Str\n",
    "        Concetation represented by '|'\n",
    "     \n",
    "    Requirements\n",
    "    ------------\n",
    "    -NoError from pj_funcs.py\n",
    "    -index_n from pj_funcs.py\n",
    "    -Numpy as np\n",
    "    -hl7\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Initialize empty output\n",
    "    output = ''\n",
    "    \n",
    "    # Read in field\n",
    "    field_str = field[0]\n",
    "    \n",
    "    # Check to see if the field exists in our message\n",
    "    if NoError(index,m,field_str):\n",
    "        \n",
    "        # Set the field equal to 'fi'\n",
    "        fi = m[field_str]\n",
    "        \n",
    "        # If the field repeats, it has a non-zero length. Loop through its length 1 by 1\n",
    "        for u in np.arange(0,len(fi)):\n",
    "            \n",
    "            # Identify the total index by summing strings: field, loop_number, rest_index\n",
    "            tot_index = field+[u]+rest_index\n",
    "            \n",
    "            # Make sure message can be indexed by the total index\n",
    "            if NoError(index_n,m,tot_index):\n",
    "                \n",
    "                #  If the indexing up to the 2nd to last element returns a string, accept it.  Call it 'output'\n",
    "                if type(index_n(m,tot_index[:-1])) == str:\n",
    "                    full = index_n(m,tot_index[:-1])\n",
    "                    \n",
    "                    # If this string, 'full', has non-zero length, add it to our output and end with '|'\n",
    "                    if len(full)>0:\n",
    "                        output += full\n",
    "                        output += '|'\n",
    "                        \n",
    "                # Normally, we will take the exact, full-indexed value.  Call it 'output'\n",
    "                else:\n",
    "                    full = str(index_n(m,tot_index))\n",
    "                    \n",
    "                    # If this string, 'full', has non-zero length, add it to our output and end with '|'\n",
    "                    if len(full)>0:\n",
    "                        output += full\n",
    "                        output += '|'\n",
    "                        \n",
    "                # Go back and loop through more repeated fields until no more exist\n",
    "                \n",
    "    # if non-zero length output, clean up last trailing '|' character\n",
    "    if len(output)>0:\n",
    "        if output[-1] == '|':\n",
    "            output = output[:-1]\n",
    "            \n",
    "    # Return output.  If none found, this will be '' (empty string)\n",
    "    return output\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "\n",
    "def DI_One(ind,m,df,z,col_name):\n",
    "    \n",
    "    '''\n",
    "    Returns the element value of 'm' indexed by 'ind'.\n",
    "    Updates the dataframe 'df' cell value indexed by 'z' and 'col_name'\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ind: list, required, complete index path (as list) to desired element\n",
    "    m: hl7 type object, required, m = hl7.parse(some_message)\n",
    "    df:  pandas DataFrame, required\n",
    "    z:  int, required, valid integer row index of df\n",
    "    col_name: str, required, valid column in df\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Str\n",
    "        Element\n",
    "        \n",
    "    Output\n",
    "    ------\n",
    "    Updates dataframe\n",
    "        df.loc[z,col_name] = Element\n",
    "     \n",
    "    Requirements\n",
    "    ------------\n",
    "    -Index_pull from pj_funcs.py\n",
    "    -Pandas\n",
    "    -hl7\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Call the index on the message.\n",
    "    obj = Index_pull(ind,m)\n",
    "    \n",
    "    # See if the 'obj' is an actual non-zero thing.\n",
    "    if len(obj)>0:\n",
    "        \n",
    "        # If so, append to the row_z, col_colname in Dataframe, df\n",
    "        df.loc[z,col_name] = obj\n",
    "        \n",
    "    # Else:  Do nothing.\n",
    "    \n",
    "    # Return the object.  If none found, will return empty str, '' with no df update\n",
    "    return obj\n",
    "\n",
    "####################################################################\n",
    "\n",
    "def DI_One_CONC(field,ind,m,df,z,col_name):\n",
    "    \n",
    "    '''\n",
    "    Returns the CONCETATED element value of 'm' indexed by its respective\n",
    "        repeating field, 'field', and 'ind'.\n",
    "    Updates the dataframe 'df' cell value indexed by 'z' and 'col_name'\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    field: list (with one element), required, for non-empty return choose valid 3 letter HL7 field\n",
    "    ind: list, required, complete index path (as list) to desired element\n",
    "    m: hl7 type object, required, m = hl7.parse(some_message)\n",
    "    df:  pandas DataFrame, required\n",
    "    z:  int, required, valid integer row index of df\n",
    "    col_name: str, required, valid column in df\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Str\n",
    "        Concetated_Element separated by '|'\n",
    "        \n",
    "    Output\n",
    "    ------\n",
    "    Updates dataframe\n",
    "        df.loc[z,col_name] = Concetated_Element\n",
    "     \n",
    "    Requirements\n",
    "    ------------\n",
    "    -Index_pull_CONC from pj_funcs.py\n",
    "    -Pandas\n",
    "    -hl7\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Call the index on the message.\n",
    "    obj = Index_pull_CONC(field,ind,m)\n",
    "    \n",
    "    # See if the 'obj' is an actual non-zero thing.\n",
    "    if len(obj)>0:\n",
    "        \n",
    "        # If so, append to the row_z, col_colname in Dataframe, df\n",
    "        df.loc[z,col_name] = obj\n",
    "        \n",
    "    # Else:  Do nothing.\n",
    "    \n",
    "    # Return the object\n",
    "    return obj"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
